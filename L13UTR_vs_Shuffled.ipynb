{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Flatten,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping # early stopping\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 333\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "def one_hot_dna(sequence):\n",
    "    seq_array = np.array(list(sequence))\n",
    "\n",
    "    # one hot encoding\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    # reshape because that's what OneHotEncoder likes\n",
    "    seq_array = seq_array.reshape(len(seq_array), 1)\n",
    "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array)\n",
    "    return onehot_encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_link/L1/data/all_50_last.txt', 'r') as file:\n",
    "    target_sequences = np.array([line.strip().upper() for line in file.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_link/L1/data/all_shuffled_50_last.txt', 'r') as file:\n",
    "    non_target_sequences = np.array([line.strip().upper() for line in file.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_sequences.shape[0] > non_target_sequences.shape[0]:\n",
    "    target_sequences_n = np.random.choice(\n",
    "        target_sequences,\n",
    "        non_target_sequences.shape[0],\n",
    "    )\n",
    "    non_target_sequences_n = non_target_sequences\n",
    "else:\n",
    "    target_sequences_n = target_sequences\n",
    "    non_target_sequences_n = np.random.choice(\n",
    "        non_target_sequences,\n",
    "        target_sequences.shape[0],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "X = np.concatenate((target_sequences_n, non_target_sequences_n))\n",
    "Y = pd.Series(np.append(\n",
    "    np.full(target_sequences_n.shape[0], 1),\n",
    "    np.full(non_target_sequences_n.shape[0], 0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([one_hot_dna(line) for line in X])\n",
    "Y = keras.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13244, 50, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.VERSION)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "seq_len = len(X[0]) # 50\n",
    "nucleotides_count = len(X[0][0]) # 4\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexshein/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/alexshein/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(50, 5, activation='relu', input_shape=(seq_len, nucleotides_count)))\n",
    "model.add(MaxPooling1D(3))\n",
    "# model.add(Conv1D(seq_len, 3, activation='relu',))\n",
    "# model.add(MaxPooling1D())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 46, 50)            1050      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 15, 50)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                48064     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 49,244\n",
      "Trainable params: 49,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8939 samples, validate on 994 samples\n",
      "WARNING:tensorflow:From /home/alexshein/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "8939/8939 [==============================] - 0s 51us/sample - loss: 0.3450 - acc: 0.8514 - val_loss: 0.1460 - val_acc: 0.9537\n",
      "Epoch 2/10\n",
      "8939/8939 [==============================] - 0s 34us/sample - loss: 0.1401 - acc: 0.9493 - val_loss: 0.0705 - val_acc: 0.9748\n",
      "Epoch 3/10\n",
      "8939/8939 [==============================] - 0s 33us/sample - loss: 0.0866 - acc: 0.9728 - val_loss: 0.0538 - val_acc: 0.9789\n",
      "Epoch 4/10\n",
      "8939/8939 [==============================] - 0s 34us/sample - loss: 0.0685 - acc: 0.9774 - val_loss: 0.0460 - val_acc: 0.9819\n",
      "Epoch 5/10\n",
      "8939/8939 [==============================] - 0s 34us/sample - loss: 0.0574 - acc: 0.9801 - val_loss: 0.0317 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "8939/8939 [==============================] - 0s 34us/sample - loss: 0.0512 - acc: 0.9839 - val_loss: 0.0283 - val_acc: 0.9889\n",
      "Epoch 7/10\n",
      "8939/8939 [==============================] - 0s 35us/sample - loss: 0.0489 - acc: 0.9833 - val_loss: 0.0291 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "8939/8939 [==============================] - 0s 34us/sample - loss: 0.0400 - acc: 0.9883 - val_loss: 0.0227 - val_acc: 0.9899\n",
      "Epoch 9/10\n",
      "8939/8939 [==============================] - 0s 35us/sample - loss: 0.0395 - acc: 0.9872 - val_loss: 0.0236 - val_acc: 0.9879\n",
      "Epoch 10/10\n",
      "8939/8939 [==============================] - 0s 35us/sample - loss: 0.0376 - acc: 0.9858 - val_loss: 0.0207 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311/3311 [==============================] - 0s 9us/sample - loss: 0.0425 - acc: 0.9840\n",
      "\n",
      "\n",
      "Test score: 0.042463574952290375\n",
      "Test accuracy: 0.98399276\n"
     ]
    }
   ],
   "source": [
    "# New\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
