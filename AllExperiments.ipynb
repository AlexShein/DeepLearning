{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from confusion_matrix import plot_confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # early stopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling1D,\n",
    "    Input,\n",
    "    MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "\n",
    "# rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 333\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_RESULTS_FOLDER = 'csv_results'\n",
    "EarlyStoppingCallback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "SEQ_LEN = 50\n",
    "NUCLEOTIDES_COUNT = 4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 42, 50)            1850      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 1,952\n",
      "Trainable params: 1,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv1D(50, 9, activation='relu', input_shape=(SEQ_LEN, NUCLEOTIDES_COUNT)))\n",
    "model0.add(GlobalAveragePooling1D())\n",
    "model0.add(Dropout(0.5))\n",
    "model0.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model0.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 42, 50)            1850      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,244\n",
      "Trainable params: 5,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv1D(50, 9, activation='relu', input_shape=(SEQ_LEN, NUCLEOTIDES_COUNT)))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 50, 50)            1850      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 16, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 14, 50)            7550      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 12,794\n",
      "Trainable params: 12,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv1D(50, 9, activation='relu', padding='same', input_shape=(SEQ_LEN, NUCLEOTIDES_COUNT)))\n",
    "model2.add(MaxPooling1D(3))\n",
    "model2.add(Conv1D(50, 3, activation='relu'))\n",
    "model2.add(GlobalAveragePooling1D())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 42, 50)            1850      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 14, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 12, 50)            7550      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4, 50)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 2, 50)             7550      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 20,344\n",
      "Trainable params: 20,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv1D(50, 9, activation='relu', input_shape=(SEQ_LEN, NUCLEOTIDES_COUNT)))\n",
    "model3.add(MaxPooling1D(3))\n",
    "model3.add(Conv1D(50, 3, activation='relu'))\n",
    "model3.add(MaxPooling1D(3))\n",
    "model3.add(Conv1D(50, 3, activation='relu',))\n",
    "model3.add(GlobalAveragePooling1D())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model3.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    '3_CNN_Layers': model3,\n",
    "    '2_CNN_Layers': model2,\n",
    "    '1_CNN_Layer': model1,\n",
    "    '1_CNN_Layer_Simple': model0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_dna(sequence):\n",
    "    seq_array = np.array(list(sequence))\n",
    "\n",
    "    # one hot encoding\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    # reshape because that's what OneHotEncoder likes\n",
    "    seq_array = seq_array.reshape(len(seq_array), 1)\n",
    "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array)\n",
    "    return onehot_encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframes(target_pathes, non_target_pathes):\n",
    "\n",
    "    target_sequences = None\n",
    "    \n",
    "    for target_path in target_pathes:\n",
    "        with open(target_path, 'r') as file:\n",
    "            read_sequences = np.array([line.strip().upper() for line in file.readlines() if all(base in set(line) for base in 'ACTG')])\n",
    "            if target_sequences is not None:\n",
    "                target_sequences = np.concatenate([\n",
    "                        target_sequences,\n",
    "                        read_sequences\n",
    "                    ])\n",
    "            else:\n",
    "                target_sequences = read_sequences\n",
    "            \n",
    "    non_target_sequences = None\n",
    "    for non_target_path in non_target_pathes:\n",
    "        with open(non_target_path, 'r') as file:\n",
    "            read_sequences = np.array([line.strip().upper() for line in file.readlines() if all(base in set(line) for base in 'ACTG')])\n",
    "            if non_target_sequences is not None:\n",
    "                non_target_sequences = np.concatenate([\n",
    "                        non_target_sequences,\n",
    "                        read_sequences\n",
    "                    ]) \n",
    "            else:\n",
    "                non_target_sequences = read_sequences\n",
    "                                    \n",
    "    return (target_sequences, non_target_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_datasets(target_sequences, non_target_sequences):\n",
    "    \n",
    "    if target_sequences.shape[0] > non_target_sequences.shape[0]:\n",
    "        target_sequences_n = np.random.choice(\n",
    "            target_sequences,\n",
    "            non_target_sequences.shape[0],\n",
    "        )\n",
    "        non_target_sequences_n = non_target_sequences\n",
    "    else:\n",
    "        target_sequences_n = target_sequences\n",
    "        non_target_sequences_n = np.random.choice(\n",
    "            non_target_sequences,\n",
    "            target_sequences.shape[0],\n",
    "        )\n",
    "\n",
    "    X = np.concatenate((target_sequences_n, non_target_sequences_n))\n",
    "    Y = pd.Series(np.append(\n",
    "        np.full(target_sequences_n.shape[0], 1),\n",
    "        np.full(non_target_sequences_n.shape[0], 0))\n",
    "    )\n",
    "    \n",
    "    X = np.array([one_hot_dna(line) for line in X])\n",
    "    Y = keras.utils.to_categorical(Y)\n",
    "    \n",
    "    return (X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(X, Y, model):\n",
    "    # ROC vars\n",
    "    tprs = []\n",
    "    aucs, acc, rec, prec = [], [], [], []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    i = 0\n",
    "    # Precision-recall vars\n",
    "    precisions = []\n",
    "    best_precision = {\"precision_score\": 0.0, \"precision\": None, \"recall\": None}\n",
    "\n",
    "    folded_data = KFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True)\n",
    "\n",
    "    for k, (train, test) in enumerate(folded_data.split(X, Y)):\n",
    "        Y_test_flat = np.array(list(map(lambda x: x[1] == 1 and 1 or 0, Y[test])))\n",
    "        model.fit(\n",
    "            X[train],\n",
    "            Y[train],\n",
    "            # Keras special args\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            verbose=1,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[EarlyStoppingCallback],\n",
    "            )\n",
    "        probas_ = model.predict(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test_flat, probas_[:, 1])\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        Y_pred = model.predict_classes(X[test])\n",
    "\n",
    "        acc.append(accuracy_score(Y_test_flat, Y_pred))\n",
    "        prec.append(precision_score(Y_test_flat, Y_pred))\n",
    "        rec.append(recall_score(Y_test_flat, Y_pred))\n",
    "        # Compute precision, recall\n",
    "        precision, recall, _ = precision_recall_curve(Y_test_flat, probas_[:, 1])\n",
    "        average_precision = average_precision_score(Y_test_flat, probas_[:, 1])\n",
    "        if average_precision > best_precision[\"precision_score\"]:\n",
    "            best_precision[\"precision\"] = precision\n",
    "            best_precision[\"recall\"] = recall\n",
    "            best_precision[\"precision_score\"] = average_precision\n",
    "        precisions.append(average_precision)\n",
    "        \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "\n",
    "        \n",
    "    return mean_fpr, mean_tpr, best_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(datasets, model, model_name, write_results=True):\n",
    "    '''\n",
    "    datasets: a dict like {\n",
    "    'L1': 'data_link/L1/data/all_50_last.txt',\n",
    "    'p_pseudo': 'pseudogenes_50_last.txt',\n",
    "    }\n",
    "    model: keras model\n",
    "    model_name: str\n",
    "    '''\n",
    "    # Restart session to ensure that model is clean\n",
    "    #     keras.backend.clear_session()\n",
    "\n",
    "    CLASS_1, CLASS_2 = datasets.keys()\n",
    "    target_pathes, non_target_pathes = datasets.values()\n",
    "    # Read data\n",
    "    target_sequences, non_target_sequences = read_dataframes(target_pathes, non_target_pathes)\n",
    "    X, Y = normalize_datasets(target_sequences, non_target_sequences)\n",
    "\n",
    "    # Use 5 fold to evaluate model\n",
    "    mean_fpr, mean_tpr, best_precision = compute_metrics(X, Y, model)\n",
    "\n",
    "    if write_results:\n",
    "        # Create file names\n",
    "        CSV_FILE_SUBNAME_OBJECTS = f\"{CLASS_1}_vs_{CLASS_2}\" # \"True_vs_False\"\n",
    "        CSV_FILE_SUBNAME = f\"{CSV_FILE_SUBNAME_OBJECTS}__{model_name}\"\n",
    "\n",
    "        # Write results to csv\n",
    "        # ROC\n",
    "        pd.DataFrame({\n",
    "            \"fpr\": mean_fpr,\n",
    "            \"tpr\": mean_tpr\n",
    "        }).to_csv(\n",
    "            f\"{CSV_RESULTS_FOLDER}/ROC__{CSV_FILE_SUBNAME}.csv\",\n",
    "            index=False\n",
    "        )\n",
    "        # Precision-recall\n",
    "        pd.DataFrame({\n",
    "            \"precision\": best_precision[\"precision\"],\n",
    "            \"recall\": best_precision[\"recall\"]\n",
    "        }).to_csv(\n",
    "            f\"{CSV_RESULTS_FOLDER}/Precision-Recall__{CSV_FILE_SUBNAME}.csv\",\n",
    "            index=False\n",
    "        )\n",
    "        #     pd.DataFrame(fi).to_csv(\"Feature_importance__{0}.csv\".format(CSV_FILE_SUBNAME), index=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "    'L1': ['data_link/L1/data/all_50_last.txt',],\n",
    "    'p_pseudo': ['pseudogenes_50_last.txt',],\n",
    "    },\n",
    "    {\n",
    "    'L1': ['data_link/L1/data/all_50_last.txt',],\n",
    "    'mRNA': ['KnownGene_50_last.txt',],\n",
    "    },\n",
    "    {\n",
    "    'L1_p_pseudo': ['data_link/L1/data/all_50_last.txt', 'pseudogenes_50_last.txt',],\n",
    "    'shuffled': ['data_link/L1/data/all_shuffled_50_last.txt', 'pseudogenes_50_last_shuffled.txt',],\n",
    "    },\n",
    "    {\n",
    "    'L1_mRNA': ['data_link/L1/data/all_50_last.txt', 'KnownGene_50_last.txt',],\n",
    "    'shuffled': ['data_link/L1/data/all_shuffled_50_last.txt', 'KnownGene_50_last_shuffled.txt',],\n",
    "    },\n",
    "    {\n",
    "    'mRNA': ['KnownGene_50_last.txt',],\n",
    "    'shuffled': ['KnownGene_50_last_shuffled.txt',],\n",
    "    },\n",
    "    {\n",
    "    'p_pseudo': ['pseudogenes_50_last.txt',],\n",
    "    'shuffled': ['pseudogenes_50_last_shuffled.txt',],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    for experiment_dataset in experiments:\n",
    "        run_experiment(experiment_dataset, model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
